{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import collections\n",
    "from collections import Counter\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Desktop/raw_kickstarter_data/2017-10\n",
      "../Desktop/raw_kickstarter_data/2018-05\n",
      "../Desktop/raw_kickstarter_data/2018-02\n",
      "../Desktop/raw_kickstarter_data/2017-11\n",
      "../Desktop/raw_kickstarter_data/2018-03\n",
      "../Desktop/raw_kickstarter_data/2018-04\n",
      "../Desktop/raw_kickstarter_data/2016-11\n",
      "../Desktop/raw_kickstarter_data/2019-03\n",
      "../Desktop/raw_kickstarter_data/2019-04\n",
      "../Desktop/raw_kickstarter_data/2016-10\n",
      "../Desktop/raw_kickstarter_data/2019-02\n",
      "../Desktop/raw_kickstarter_data/2016-04\n",
      "../Desktop/raw_kickstarter_data/2016-03\n",
      "../Desktop/raw_kickstarter_data/2016-05\n",
      "../Desktop/raw_kickstarter_data/2018-10\n",
      "../Desktop/raw_kickstarter_data/2017-02\n",
      "../Desktop/raw_kickstarter_data/2017-05\n",
      "../Desktop/raw_kickstarter_data/2018-11\n",
      "../Desktop/raw_kickstarter_data/2017-04\n",
      "../Desktop/raw_kickstarter_data/2017-03\n",
      "../Desktop/raw_kickstarter_data/2018-08\n",
      "../Desktop/raw_kickstarter_data/2018-01\n",
      "../Desktop/raw_kickstarter_data/2018-06\n",
      "../Desktop/raw_kickstarter_data/2018-07\n",
      "../Desktop/raw_kickstarter_data/2018-09\n",
      "../Desktop/raw_kickstarter_data/2017-12\n",
      "../Desktop/raw_kickstarter_data/2016-12\n",
      "../Desktop/raw_kickstarter_data/2019-01\n",
      "../Desktop/raw_kickstarter_data/2016-09\n",
      "../Desktop/raw_kickstarter_data/2016-07\n",
      "../Desktop/raw_kickstarter_data/2016-06\n",
      "../Desktop/raw_kickstarter_data/2016-01\n",
      "../Desktop/raw_kickstarter_data/2016-08\n",
      "../Desktop/raw_kickstarter_data/2017-06\n",
      "../Desktop/raw_kickstarter_data/2017-01\n",
      "../Desktop/raw_kickstarter_data/2017-08\n",
      "../Desktop/raw_kickstarter_data/2017-09\n",
      "../Desktop/raw_kickstarter_data/2017-07\n",
      "../Desktop/raw_kickstarter_data/2018-12\n"
     ]
    }
   ],
   "source": [
    "# load data as dataframe\n",
    "path1 = \"../Desktop/raw_kickstarter_data/\"\n",
    "path2 = \"../Desktop/cleaned_kickstarter_data/\"\n",
    "count = 0\n",
    "for foldername in glob.glob(path1 + \"*\"):\n",
    "    print(foldername)\n",
    "    # import data\n",
    "    frames = []\n",
    "    for filename in glob.glob(foldername + \"/*.csv\"):\n",
    "        if count == 0:\n",
    "            df = pd.read_csv(filename)\n",
    "            count += 1\n",
    "        else:\n",
    "            df = pd.read_csv(filename, header = 0)\n",
    "        frames.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarinaliu/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "### INITIAL DATA CLEANING\n",
    "\n",
    "projects_id = []\n",
    "df1 = pd.DataFrame()\n",
    "df1_success = pd.DataFrame()\n",
    "df1_fail = pd.DataFrame()\n",
    "\n",
    "# 2016-2019 data\n",
    "df1 = pd.concat(frames, axis = 0, join = 'inner')\n",
    "\n",
    "# remove unnecessary columns\n",
    "to_drop = ['blurb','currency','currency_symbol','disable_communication','launched_at',\n",
    "           'location','photo','pledged','profile','slug','spotlight','staff_pick',\n",
    "           'state_changed_at','static_usd_rate']\n",
    "df1.drop(to_drop, inplace=True, axis=1)\n",
    "\n",
    "category_id1 = []\n",
    "creator_id1 = []\n",
    "category_name1 = []\n",
    "url1 = []\n",
    "\n",
    "# extract category id\n",
    "for c1 in df1['category']:\n",
    "    start_idx = c1.find('\"id\":') + 5\n",
    "    end_idx1 = c1.find('\"position\":') - 1\n",
    "    end_idx2 = c1.find('\"name\":') - 1\n",
    "    end_idx = 0\n",
    "    if (start_idx < end_idx1 and start_idx < end_idx2):\n",
    "        end_idx = min(end_idx1, end_idx2)\n",
    "    else:\n",
    "        end_idx = max(end_idx1, end_idx2)\n",
    "    category_id1.append(c1[start_idx:end_idx])\n",
    "\n",
    "# extract creator id\n",
    "for c2 in df1['creator']:\n",
    "    start_idx = c2.find('\"id\":') + 5\n",
    "    end_idx1 = c2.find('\"avatar\":') - 1\n",
    "    end_idx2 = c2.find('\"name\":') - 1\n",
    "    end_idx = 0\n",
    "    if (start_idx < end_idx1 and start_idx < end_idx2):\n",
    "        end_idx = min(end_idx1, end_idx2)\n",
    "    else:\n",
    "        end_idx = max(end_idx1, end_idx2)\n",
    "    creator_id1.append(c2[start_idx:end_idx])\n",
    "\n",
    "# extract category name\n",
    "for c3 in df1['category']:\n",
    "    start_idx = c3.find('\"slug\":') + 8\n",
    "    end_idx = c3.find('\"position\":') - 2\n",
    "    category_name1.append(c3[start_idx:end_idx])\n",
    "\n",
    "# extract project url\n",
    "for u1 in df1['urls']:\n",
    "    start_idx = u1.find('\"project\":\"') + 11\n",
    "    end_idx = u1.find('\"rewards\":') - 2\n",
    "    url1.append(u1[start_idx:end_idx])\n",
    "\n",
    "# define new columns\n",
    "df1['category_id'] = category_id1\n",
    "df1['creator_id'] = creator_id1\n",
    "df1['category_name'] = category_name1\n",
    "df1['url'] = url1\n",
    "\n",
    "# rearranging columns\n",
    "df1 = df1[['creator_id','id','name','created_at','deadline','category_id','category_name',\n",
    "           'goal','usd_pledged','backers_count','state','url', 'country']]\n",
    "\n",
    "# convert epoch to datetime\n",
    "df1['created_at'] = pd.to_datetime(df1['created_at'],unit='s')\n",
    "df1['deadline'] = pd.to_datetime(df1['deadline'],unit='s')\n",
    "\n",
    "# only keep US companies that were not cancelled\n",
    "df1 = df1.loc[(df1['country'] == 'US') & (df1['state'].isin(['successful','failed'])) & \n",
    "                  (df1['goal'] > 25000) & (df1['usd_pledged'] > 2500)]\n",
    "df1_success = df1.loc[(df1['country'] == 'US') & (df1['state'] == 'successful') & \n",
    "                      (df1['goal'] > 25000) & (df1['usd_pledged'] > 2500)]\n",
    "df1_fail = df1.loc[(df1['country'] == 'US') & (df1['state'] == 'failed') & \n",
    "                       (df1['goal'] > 25000)& (df1['usd_pledged'] > 2500)]\n",
    "df1.drop(['country'], inplace = True, axis = 1)\n",
    "df1_success.drop(['country'], inplace = True, axis = 1)\n",
    "df1_fail.drop(['country'], inplace = True, axis = 1)\n",
    "\n",
    "# remove duplicates\n",
    "df1 = df1.drop_duplicates('id')\n",
    "projects_id = projects_id + list(df1['id'])\n",
    "df1_success = df1_success.drop_duplicates('id')\n",
    "df1_fail = df1_fail.drop_duplicates('id')\n",
    "\n",
    "# first sort by category id, then sort by date\n",
    "df1.sort_values(['category_id', 'deadline'], ascending = [True, True], inplace = True)\n",
    "df1_success.sort_values(['category_id', 'deadline'], ascending = [True, True], inplace = True)\n",
    "df1_fail.sort_values(['category_id', 'deadline'], ascending = [True, True], inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to csv file\n",
    "df1.to_csv(path2 + \"/All.csv\", index = False) # 7722\n",
    "df1_success.to_csv(path2 + \"/All_Success.csv\", index = False) # 5348\n",
    "df1_fail.to_csv(path2 + \"/All_Fail.csv\", index = False)# 2374\n",
    "\n",
    "# 7722 unique projects that were not cancelled in US with at least $25,000 goal \n",
    "# and $2500 pledged from 10/4/2009 - 12/12/2018\n",
    "# 5348 unique successes\n",
    "# 2374 unique failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of success:\n",
      "0.6925666925666926\n"
     ]
    }
   ],
   "source": [
    "### CALCULATION - PROBABILITY OF SUCCESS\n",
    "\n",
    "# probability of success per category\n",
    "category_multi_projects = []\n",
    "category_success_rate = {}\n",
    "category_freq = df1['category_name'].value_counts().to_dict()\n",
    "category_success_freq = df1_success['category_name'].value_counts().to_dict()\n",
    "category_fail_freq = df1_fail['category_name'].value_counts().to_dict()\n",
    "# creating list of categories with more than one project\n",
    "for i in category_freq:\n",
    "    if category_freq[i] > 1:\n",
    "        category_multi_projects.append(i)\n",
    "for j in category_freq:\n",
    "    if j in category_success_freq.keys():\n",
    "        category_success_rate[j] = category_success_freq[j] / category_freq[j]\n",
    "    else: # no successes in these categories\n",
    "        category_success_rate[j] = 0\n",
    "    \n",
    "# probability of success for aggregate categories\n",
    "success_rate = len(df1_success) / len(df1)\n",
    "print(\"Probability of success:\")\n",
    "print(success_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CATEGORIES RESEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarinaliu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "### COMPETITION VS. NON-COMPETITION\n",
    "\n",
    "df2 = df1.copy() # >1 project per category\n",
    "df2_1 = df1.copy() # 1 project per category\n",
    "\n",
    "category_single_projects = []\n",
    "for i in category_freq:\n",
    "    if category_freq[i] == 1:\n",
    "        category_single_projects.append(i)\n",
    "df2 = df2.loc[df2['category_name'].isin(category_multi_projects)]\n",
    "df2_1 = df2_1.loc[df2_1['category_name'].isin(category_single_projects)]\n",
    "\n",
    "df3 = pd.DataFrame()\n",
    "df3_1 = pd.DataFrame()\n",
    "count = 0\n",
    "for j in category_multi_projects:\n",
    "    temp = df2.loc[df2['category_name'] == j]\n",
    "    temp['overlap'] = (temp['deadline'].shift() - temp['created_at']) > timedelta(0)\n",
    "    temp1 = temp.loc[temp['overlap'] == True]\n",
    "    temp2 = temp.loc[temp['overlap'] == False]\n",
    "    temp1.drop(['overlap'], inplace = True, axis = 1)\n",
    "    temp2.drop(['overlap'], inplace = True, axis = 1)\n",
    "    if len(temp1) > 0:\n",
    "        df3 = df3.append(temp1) # overlapping projects within category\n",
    "    if len(temp2) > 0:\n",
    "        df3_1 = df3_1.append(temp2) # non-overlapping projects within category\n",
    "                 \n",
    "df3_1 = df3_1.append(df2_1) # single + non-overlapping projects\n",
    "            \n",
    "df3_success = df3.loc[df3['state'] == 'successful'] # successful subset for competing projects\n",
    "df3_fail = df3.loc[df3['state'] == 'failed'] # failed subset for competing projects\n",
    "df3_1_success = df3_1.loc[df3_1['state'] == 'successful'] # successful subset for non-competing projects\n",
    "df3_1_fail = df3_1.loc[df3_1['state'] == 'failed'] # failed subset for non-competing projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to csv file\n",
    "# projects in the same category with overlapping time series\n",
    "df3.to_csv(path2 + \"/All_Competition.csv\", index = False) # 6615\n",
    "df3_success.to_csv(path2 + \"/Success_Competition.csv\", index = False) # 4578\n",
    "df3_fail.to_csv(path2 + \"/Fail_Competition.csv\", index = False) # 2037\n",
    "df3_1.to_csv(path2 + \"/All_Non_Competition.csv\", index = False) # 1107\n",
    "df3_1_success.to_csv(path2 + \"/Success_Non_Competition.csv\", index = False) # 770\n",
    "df3_1_fail.to_csv(path2 + \"/Fail_Non_Competition.csv\", index = False) # 337\n",
    "\n",
    "# 6615 projects in the same category with overlapping time series\n",
    "# 4578 of these projects were successful\n",
    "# 2037 of these projects failed\n",
    "\n",
    "# 1107 projects had no competition\n",
    "# 770 of these projects were successful\n",
    "# 337 of these projects failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "competition_category_success_rate = {}\n",
    "competition_category_freq = df3['category_name'].value_counts().to_dict()\n",
    "competition_category_success_freq = df3_success['category_name'].value_counts().to_dict()\n",
    "competition_category_fail_freq = df3_fail['category_name'].value_counts().to_dict()\n",
    "\n",
    "non_competition_category_success_rate = {}\n",
    "non_competition_category_freq = df3_1['category_name'].value_counts().to_dict()\n",
    "non_competition_category_success_freq = df3_1_success['category_name'].value_counts().to_dict()\n",
    "non_competition_category_fail_freq = df3_1_fail['category_name'].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CALCULATION - NUMBER OF PROJECTS\n",
    "\n",
    "# all\n",
    "category_num = dict()\n",
    "for k, v in category_freq.items():\n",
    "    category_num[k] = [v]\n",
    "\n",
    "# all success\n",
    "for k, v in category_freq.items():\n",
    "    if k in category_success_freq.keys():\n",
    "        category_num[k].append(category_success_freq[k])\n",
    "    else: # no successes in these categories\n",
    "        category_num[k].append(0)\n",
    "# all fail        \n",
    "for k, v in category_freq.items():\n",
    "    if k in category_fail_freq.keys():\n",
    "        category_num[k].append(category_fail_freq[k])\n",
    "    else: # no successes in these categories\n",
    "        category_num[k].append(0)\n",
    "\n",
    "#-------------------\n",
    "\n",
    "# competition\n",
    "for k, v in category_freq.items():\n",
    "    if k in competition_category_freq.keys():\n",
    "        category_num[k].append(competition_category_freq[k])\n",
    "    else: # no successes in these categories\n",
    "        category_num[k].append(0)\n",
    "        \n",
    "# competition success\n",
    "for k, v in category_freq.items():\n",
    "    if k in competition_category_success_freq.keys():\n",
    "        category_num[k].append(competition_category_success_freq[k])\n",
    "    else: # no successes in these categories\n",
    "        category_num[k].append(0)\n",
    "        \n",
    "# competition fail\n",
    "for k, v in category_freq.items():\n",
    "    if k in competition_category_fail_freq.keys():\n",
    "        category_num[k].append(competition_category_fail_freq[k])\n",
    "    else: # no successes in these categories\n",
    "        category_num[k].append(0)\n",
    "        \n",
    "#-------------------\n",
    "\n",
    "# non-competition\n",
    "for k, v in category_freq.items():\n",
    "    if k in non_competition_category_freq.keys():\n",
    "        category_num[k].append(non_competition_category_freq[k])\n",
    "    else:\n",
    "        category_num[k].append(0)\n",
    "        \n",
    "# non-competition success\n",
    "for k, v in category_freq.items():\n",
    "    if k in non_competition_category_success_freq.keys():\n",
    "        category_num[k].append(non_competition_category_success_freq[k])\n",
    "    else:\n",
    "        category_num[k].append(0)\n",
    "        \n",
    "# non-competition fail\n",
    "for k, v in category_freq.items():\n",
    "    if k in non_competition_category_fail_freq.keys():\n",
    "        category_num[k].append(non_competition_category_fail_freq[k])\n",
    "    else:\n",
    "        category_num[k].append(0)\n",
    "\n",
    "# ------------------\n",
    "        \n",
    "# Write calculations to csv files\n",
    "\n",
    "df7 = pd.DataFrame(category_num.items(), columns = ['category_name', 'number'])\n",
    "with open(path2 + \"/Number_Category.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Category','All','Success','Fail','Competition', \\\n",
    "                     'Competition Success', 'Competition Fail', 'Non-Competition',\\\n",
    "                    'Non-Competition Success', 'Non-Competition Fail'])\n",
    "    for i in range(len(df7['number'])):\n",
    "        lst1 = list(df7['number'])[i]\n",
    "        if lst1[3] not in ['1.0','1','0.0','0']: # > 0 competing projects\n",
    "            lst2 = list(category_freq.keys())\n",
    "            lst1.insert(0, str(lst2[i]))\n",
    "            writer.writerow(lst1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CALCULATION - PROPORTION\n",
    "\n",
    "# all\n",
    "category_frac = dict()\n",
    "for k, v in category_freq.items():\n",
    "    category_frac[k] = [v / len(df1)]\n",
    "\n",
    "# success\n",
    "for k, v in category_freq.items():\n",
    "    if k in category_success_freq.keys():\n",
    "        category_frac[k].append(category_success_freq[k] / len(df1_success))\n",
    "    else: # no successes in these categories\n",
    "        category_frac[k].append(0)\n",
    "# fail        \n",
    "for k, v in category_freq.items():\n",
    "    if k in category_fail_freq.keys():\n",
    "        category_frac[k].append(category_fail_freq[k] / len(df1_fail))\n",
    "    else: # no successes in these categories\n",
    "        category_frac[k].append(0)\n",
    "        \n",
    "#-------------------\n",
    "\n",
    "# competition\n",
    "for k, v in category_freq.items():\n",
    "    if k in competition_category_freq.keys():\n",
    "        category_frac[k].append(competition_category_freq[k] / len(df3))\n",
    "    else: # no successes in these categories\n",
    "        category_frac[k].append(0)\n",
    "        \n",
    "# competition success\n",
    "for k, v in category_freq.items():\n",
    "    if k in competition_category_success_freq.keys():\n",
    "        category_frac[k].append(competition_category_success_freq[k] / len(df3_success))\n",
    "    else: # no successes in these categories\n",
    "        category_frac[k].append(0)\n",
    "        \n",
    "# competition fail\n",
    "for k, v in category_freq.items():\n",
    "    if k in competition_category_fail_freq.keys():\n",
    "        category_frac[k].append(competition_category_fail_freq[k] / len(df3_fail))\n",
    "    else: # no successes in these categories\n",
    "        category_frac[k].append(0)\n",
    "        \n",
    "# ------------------\n",
    "\n",
    "# non-competition\n",
    "for k, v in category_freq.items():\n",
    "    if k in non_competition_category_freq.keys():\n",
    "        category_frac[k].append(non_competition_category_freq[k] / len(df3_1))\n",
    "    else:\n",
    "        category_frac[k].append(0)\n",
    "        \n",
    "# non-competition success\n",
    "for k, v in category_freq.items():\n",
    "    if k in non_competition_category_success_freq.keys():\n",
    "        category_frac[k].append(non_competition_category_success_freq[k] / len(df3_1_success))\n",
    "    else:\n",
    "        category_frac[k].append(0)\n",
    "        \n",
    "# non-competition fail\n",
    "for k, v in category_freq.items():\n",
    "    if k in non_competition_category_fail_freq.keys():\n",
    "        category_frac[k].append(non_competition_category_fail_freq[k] / len(df3_1_fail))\n",
    "    else:\n",
    "        category_frac[k].append(0)\n",
    "\n",
    "# ------------------\n",
    "        \n",
    "# Write calculations to csv files\n",
    "\n",
    "df8 = pd.DataFrame(category_frac.items(), columns = ['category_name', 'proportion'])\n",
    "with open(path2 + \"/Proportion_Category.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Category','All','Success','Fail','Competition', \\\n",
    "                     'Competition Success', 'Competition Fail', 'Non-Competition',\\\n",
    "                    'Non-Competition Success', 'Non-Competition Fail'])\n",
    "    for i in range(len(df8['proportion'])):\n",
    "        lst1 = list(df8['proportion'])[i]\n",
    "        if lst1[3] not in ['1.0','1','0.0','0']: # > 0 competing projects\n",
    "            lst2 = list(category_freq.keys())\n",
    "            lst1.insert(0, str(lst2[i]))\n",
    "            writer.writerow(lst1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of success conditional on competition:\n",
      "0.692063492063492\n",
      "Probability of success conditional on non-competition:\n",
      "0.6955736224028907\n",
      "Prob of success competition > non-competition for the following percentage of categories: \n",
      "35.14%\n"
     ]
    }
   ],
   "source": [
    "### CALCULATION - PROBABILITY OF SUCCESS\n",
    "\n",
    "# probability of success per category conditional on competition\n",
    "\n",
    "# creating list of categories with overlapping projects\n",
    "for i in category_freq:\n",
    "    if i in category_multi_projects:\n",
    "        if i in competition_category_success_freq.keys():\n",
    "            competition_category_success_rate[i] = competition_category_success_freq[i] / competition_category_freq[i]\n",
    "        else:  # no successes in these categories\n",
    "            competition_category_success_rate[i] = 0\n",
    "    else:\n",
    "        competition_category_success_rate[i] = 0\n",
    "    \n",
    "# probability of success for aggregate categories conditional on competition\n",
    "competition_success_rate = len(df3_success) / len(df3)\n",
    "print(\"Probability of success conditional on competition:\")\n",
    "print(competition_success_rate)\n",
    "\n",
    "# --------------\n",
    "\n",
    "# probability of success per category conditional on no competition\n",
    "\n",
    "# creating list of categories without overlapping projects\n",
    "for i in category_freq:\n",
    "    if i in category_single_projects or i in category_multi_projects:\n",
    "        if i in non_competition_category_success_freq.keys():\n",
    "            non_competition_category_success_rate[i] = non_competition_category_success_freq[i] / non_competition_category_freq[i]\n",
    "        else:  # no successes in these categories\n",
    "            non_competition_category_success_rate[i] = 0\n",
    "    else:\n",
    "        non_competition_category_success_rate[i] = 0\n",
    "    \n",
    "# probability of success for aggregate categories conditional on competition\n",
    "non_competition_success_rate = len(df3_1_success) / len(df3_1)\n",
    "print(\"Probability of success conditional on non-competition:\")\n",
    "print(non_competition_success_rate)\n",
    "\n",
    "# --------------\n",
    "\n",
    "# Write calculations to csv files\n",
    "\n",
    "subsets = [category_success_rate, competition_category_success_rate, non_competition_category_success_rate]\n",
    "\n",
    "prob_success = {}\n",
    "for k in category_success_rate.keys():\n",
    "    prob_success[k] = list(str(prob_success[k]) for prob_success in subsets)\n",
    "\n",
    "df9 = pd.DataFrame(prob_success.items(), columns = ['category_name', 'prob_of_success'])\n",
    "count_compete = 0\n",
    "count_non_compete = 0\n",
    "with open(path2 + \"/Prob_Of_Success_Category.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Category','All','Competition','Non-Competition', 'Difference'])\n",
    "    lst2 = list(category_freq.keys())\n",
    "    for i in range(len(df9['prob_of_success'])):\n",
    "        lst = list(df9['prob_of_success'])[i]\n",
    "        lst1 = [ '%.4f' % float(j) for j in lst]\n",
    "        if lst1[1] not in ['1.0000','1','0.0000','0'] and lst1[2] not in ['1.0000','1','0.0000','0']: # > 0 competing/non-competing projects\n",
    "            lst1.insert(0, str(lst2[i]))\n",
    "            diff = round(float(lst1[2]) - float(lst1[3]),4)\n",
    "            lst1.insert(len(lst1),str(diff))\n",
    "            if diff > 0:\n",
    "                count_compete += 1\n",
    "            else:\n",
    "                count_non_compete += 1\n",
    "            writer.writerow(lst1)\n",
    "\n",
    "print(\"Prob of success competition > non-competition for the following percentage of categories: \")\n",
    "print(\"{:.2%}\".format(count_compete / (count_compete + count_non_compete)))\n",
    "\n",
    "# Probability of success:\n",
    "# 0.6925666925666926"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
